---
layout: post
title: "Comparing MRI and JRuby for solving math problems"
image: /assets/patterns/paisley.png
header:
  image: /assets/patterns/asanoha-400px.png
repository:
  is_project_page: true
  show_downloads: false
  repository_url: https://github.com/mzemel/iim
  zip_url: https://github.com/mzemel/iim/archive/master.zip
tags: ["data"]
keywords: data
ref: what-is-this
lang: en
category: projects
---

Back when I applied to SweetSpot (now Dexcom), I was given a code challenge of fixing up a ruby script to calculate an "incremental interquartile mean".  The "interquartile mean" is where you chop off the first and last quarter of a data set and take the mean of the middle two quarters.  By incremental, they mean that it should update as you add numbers to the data set.  The point of the exercise had 3 points:

1. Can you recalculate this number in the most efficient way possible?  Meaning, you shouldn't have to segment out the middle two quarters every time, nor should you have to calculate an average - just apply a delta as a result of processing the incoming number.
2. Can you fix up the terrible variable names and organization, making it readable and maintainable?
3. Can you make it extendable or usable in a larger application?

I was able to do all of these (struggling with the first) and got an offer, which I accepted.  That code is [available here](https://github.com/mzemel/iim)

## JRuby

I think I had too much coffee or time to kill, so I wanted to see how this performed on large sets of data when run in MRI Ruby vs. [JRuby](http://jruby.org/).  In order to leverage the multi-threading of JRuby, I converted the job to use a series of agents running in a pool.  Each agent would receive a section of the data, calculate the IQM, and all data would be collected and averaged.  This doesn't get us the exact number, but it did give me a reason to play with multi-threading so I let the logic slide a little.  I did the same for MRI Ruby, but with the caveat that the GIL prevents more than one thread from being executed at a time.

The first condition looked at the effect of data set size vs. the margin of error using this multi-agent approach.

![one](https://i.imgur.com/a8OeDQB.png)

This one is purely mathematical.  The larger the data set, the more we approximate the true average in subsets (assuming the number of sets is held constant).

Next I looked at number of agents vs. margin of error while holding the data set size constant.

![two](https://i.imgur.com/f6Qtxd8.png)

Again, these results are mathematical.  More agents = more disparity within each agent's set.  As a sanity check, I got the same results for these regardless of using MRI Ruby or JRuby.

What I was _more_ interested in was: is JRuby faster at doing these calculations, given that it's using threads across multiple cores, instead of MRI on a single core.

![three](https://i.imgur.com/xk5AUny.png)

**MRI speed**

![four](https://i.imgur.com/cMek7I7.png)

**JRuby speed**

No real difference.  That was disappointing.

However, I did re-run for very large data sets where I started to see a trend.

![five](https://i.imgur.com/LiNiTxP.png)

Here, I'm showing the results of JRuby while compared to a baseline of MRI Ruby.  It does look like when you reach large data sets, JRuby might be doing enough to make a difference.  More investigation would be required but there is a glimmer of hope.

Hope you enjoyed reading, and my full report is [located here]({{ site.url }}/assets/mri_ruby_vs_jruby_in_iqm.pdf)